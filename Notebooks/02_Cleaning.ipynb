{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquons une supression des doublons, ces derniers fausses les résulats et analyses.\n",
    "On peut voir qu'après supression il reste bien 0 doublons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([\"UNKNOWN\", \"ERROR\",], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces valeurs empêchait les conversions numériques et catégorielles.\n",
    "Les valeurs non informatives ont été assimilées à des valeurs manquantes afin de permettre un traitement cohérent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Quantity\", \"Price Per Unit\", \"Total Spent\"]\n",
    "\n",
    "for col in num_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous transformons certaines catégories en nombres, elles étaient mal catégorisées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Transaction Date\"] = pd.to_datetime(\n",
    "    df[\"Transaction Date\"], errors=\"coerce\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme cette colonne de text en date exploitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, pour chaque colonne numérique, on remplace les valeurs manquantes (nan) par la valeur mediane de la colonne. Pour eviter de fausser les resultats, ou du moins de les mener en erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Payment Method\"] = df[\"Payment Method\"].fillna(\"Unknown\")\n",
    "df[\"Location\"] = df[\"Location\"].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs manquantes des variables catégorielles présentant un taux élevé sont remplacées par la catégorie \"Unknown\" afin de conserver l'information sans introduire de biais artificiel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Item\"] = df[\"Item\"].fillna(df[\"Item\"].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la colonne Item, les valeurs \"nan\" sont remplacés par la valeur la plus fréquente de la colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Transaction Date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les dates invalides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/dataset_clean_step1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée un version intermédiaire du dataset, qui a subit nos différentes étapes de nettoyage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
